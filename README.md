# Predicato

A temporal knowledge graph library for Go with a fully local ML stack - no API keys required.

## What Makes Predicato Different

Most agentic memory libraries require external services (language models, vector databases, graph databases). Predicato has implemented embedded alternatives for all components so it can run without any external dependencies.

Predicato is **modular by design** - every component can run locally OR connect to external services. Start with the internal stack for development, then swap in cloud services for production without changing your code.

## Design

Predicato implements a **two-layer architecture** that separates raw fact extraction from graph modeling:

```
┌─────────────────────────────────────────────────────────────────┐
│                         Episodes                                 │
│              (documents, conversations, events)                  │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Entity Extraction                             │
│         (GLiNER for NER, NLP models for relationships)           │
└─────────────────────────────────────────────────────────────────┘
                              │
              ┌───────────────┴───────────────┐
              ▼                               ▼
┌─────────────────────────┐     ┌─────────────────────────────────┐
│      Fact Store         │     │        GraphModeler              │
│  (PostgreSQL/DoltGres)  │     │    (pluggable interface)         │
│                         │     │                                  │
│  • Raw extracted nodes  │     │  ┌───────────────────────────┐   │
│  • Raw extracted edges  │     │  │  • ResolveEntities        │   │
│  • Source documents     │     │  │  • ResolveRelationships   │   │
│  • Vector embeddings    │     │  │  • BuildCommunities       │   │
│                         │     │  └───────────────────────────┘   │
│  ExtractOnly=true       │     │            │                     │
│  stops here ───────────►│     │            ▼                     │
│                         │     │  ┌───────────────────────────┐   │
│  ┌───────────────────┐  │     │  │    Knowledge Graph        │   │
│  │   RAG Search      │  │     │  │  (Ladybug/Neo4j/Memgraph) │   │
│  │ (VectorChord/JSONB)│  │     │  │  • Resolved entities      │   │
│  └───────────────────┘  │     │  │  • Temporal relationships │   │
│                         │     │  │  • Communities            │   │
└─────────────────────────┘     │  └───────────────────────────┘   │
                                └─────────────────────────────────┘
```

### Why Two Layers?

**Fact Store (Layer 1)** - Stores raw extractions exactly as they were found:
- Preserves source provenance (which document, which chunk)
- Enables re-processing with different models or parameters
- Supports simple RAG without graph complexity
- Uses PostgreSQL/VectorChord for production-grade vector search

**Knowledge Graph (Layer 2)** - Stores resolved, interconnected knowledge:
- Entity resolution merges duplicates ("Bob Smith" = "Robert Smith")
- Temporal modeling tracks when facts were valid vs. when recorded
- Community detection groups related entities
- Graph traversal finds multi-hop relationships

This separation enables:
1. **Multiple views** - Generate different graph representations from the same facts
2. **Incremental updates** - Re-process only changed documents
3. **Simpler RAG** - Use `SearchFacts()` when you don't need graph features
4. **Audit trail** - Track exactly what was extracted from each source

### Bi-Temporal Model

Every fact in Predicato has two time dimensions:

| Dimension | Field | Meaning |
|-----------|-------|---------|
| **Transaction Time** | `created_at` | When the fact was recorded in the system |
| **Valid Time** | `valid_from`, `valid_to` | When the fact was true in the real world |

This enables queries like:
- "What did we know about X as of last Tuesday?" (transaction time)
- "What was true about X during Q3 2024?" (valid time)
- "Show me facts that were recorded wrong and later corrected" (both)

### Pipeline Architecture

Predicato supports two ingestion modes:

**End-to-End Pipeline** (default):
```
Episode -> Extract -> Resolve -> Graph
```

**Decoupled Pipeline** (with FactStore):
```
Episode -> Extract -> FactStore    (ExtractOnly=true)
                         |
                         v
         FactStore -> GraphModeler -> Graph
```

The decoupled mode enables:
- **Custom graph modeling**: Implement `GraphModeler` interface to customize entity resolution, relationship handling, and community detection
- **Batch processing**: Extract facts in bulk, then promote to graph on schedule
- **Re-processing**: Re-model the same facts with different parameters
- **Validation**: Test custom modelers before production use

### Entity Resolution

When adding episodes, Predicato automatically:
1. Extracts entities using GLiNER, GLInER2 (API), or NLP model prompts
2. Generates embeddings for each entity
3. Compares against existing entities (cosine similarity)
4. Merges duplicates above a threshold (default: 0.85)
5. Creates temporal edges between resolved entities

### Custom Graph Modeling

Override the default resolution logic by implementing `GraphModeler`:

```go
type GraphModeler interface {
    ResolveEntities(ctx, input) (*EntityResolutionOutput, error)
    ResolveRelationships(ctx, input) (*RelationshipResolutionOutput, error)
    BuildCommunities(ctx, input) (*CommunityOutput, error)
}

// Use with AddEpisodeOptions
client.AddEpisode(ctx, episode, &predicato.AddEpisodeOptions{
    GraphModeler: myCustomModeler,
})

// Or set as default
client, _ := predicato.NewClient(db, llm, embedder, &predicato.Config{
    DefaultGraphModeler: myCustomModeler,
})
```

Validate custom modelers before use:

```go
result, _ := client.ValidateModeler(ctx, myCustomModeler)
if !result.Valid {
    log.Fatalf("Modeler validation failed: %v", result.EntityResolution.Error)
}
```

## Components

| Component | Internal (No API) | External Services |
|-----------|-----------------|---------------------|
| **Graph Database** | Ladybug (embedded) | Neo4j, Memgraph |
| **Embeddings** | go-embedeverything | OpenAI compatible APIs, AWS bedrock, Gemini |
| **Reranking** | go-embedeverything | Jina, Cohere |
| **Text Generation** | go-rust-bert (BERT models) | OpenAI compatible APIs |
| **Entity Extraction** | GLiNER (ONNX) | GLiNER2 (API) | LLM-based extraction |
| **Fact Storage** | DoltGres (embedded) | PostgreSQL + VectorChord |

**Why choose Predicato:**
- **Security** - Don't expose your data to external services
- **Run offline** - Embedded database + local ML models = no network required
- **Swap components freely** - Same code works with local models or cloud APIs
- **Bi-temporal knowledge** - Track when facts were recorded AND when they were valid
- **Hybrid search** - Semantic + BM25 keyword + graph traversal in one query
- **Production hardened** - WAL recovery, circuit breakers, cost tracking, telemetry

## Quick Start (Internal Stack)

No API keys. No external services. Just Go and CGO.

```go
package main

import (
    "context"
    "log"
    "time"

    "github.com/soundprediction/predicato"
    "github.com/soundprediction/predicato/pkg/crossencoder"
    "github.com/soundprediction/predicato/pkg/driver"
    "github.com/soundprediction/predicato/pkg/embedder"
    "github.com/soundprediction/predicato/pkg/rustbert"
)

func main() {
    ctx := context.Background()

    // Embedded graph database (no server required)
    db, _ := driver.NewLadybugDriver("./knowledge.db", 1)
    defer db.Close(ctx)

    // Local text generation (GPT-2, no API)
    rustbertClient := rustbert.NewClient(rustbert.Config{})
    llmClient := rustbert.NewLLMAdapter(rustbertClient, "text_generation")
    defer rustbertClient.Close()

    // Local embeddings (no API)
    embedderClient, _ := embedder.NewEmbedEverythingClient(&embedder.EmbedEverythingConfig{
        Config: &embedder.Config{
            Model:      "qwen/qwen3-embedding-0.6b",
            Dimensions: 1024,
        },
    })
    defer embedderClient.Close()

    // Local reranking (no API)
    reranker, _ := crossencoder.NewEmbedEverythingClient(&crossencoder.EmbedEverythingConfig{
        Config: &crossencoder.Config{
            Model: "zhiqing/Qwen3-Reranker-0.6B-ONNX",
        },
    })
    defer reranker.Close()

    // Create client
    client, _ := predicato.NewClient(db, llmClient, embedderClient, &predicato.Config{
        GroupID:  "my-app",
        TimeZone: time.UTC,
    }, nil)
    defer client.Close(ctx)

    // Add knowledge
    client.Add(ctx, []predicato.Episode{{
        ID:        "meeting-1",
        Name:      "Team Standup",
        Content:   "Alice mentioned the API redesign is blocked on the auth team.",
        Reference: time.Now(),
        CreatedAt: time.Now(),
        GroupID:   "my-app",
    }})

    // Search with reranking
    results, _ := client.Search(ctx, "API redesign status", nil)
    
    // Rerank for better relevance
    passages := make([]string, len(results.Nodes))
    for i, node := range results.Nodes {
        passages[i] = node.Summary
    }
    ranked, _ := reranker.Rank(ctx, "API redesign status", passages)
    
    log.Printf("Top result: %s (score: %.2f)", ranked[0].Passage, ranked[0].Score)
}
```

First run downloads models (~1.7GB total). Subsequent runs use cached models.

## Quick Start (External APIs)

The same interfaces work with cloud services - just swap the implementations:

```go
package main

import (
    "context"
    "log"
    "os"
    "time"

    "github.com/soundprediction/predicato"
    "github.com/soundprediction/predicato/pkg/driver"
    "github.com/soundprediction/predicato/pkg/embedder"
    "github.com/soundprediction/predicato/pkg/nlp"
)

func main() {
    ctx := context.Background()

    // Neo4j database
    db, _ := driver.NewNeo4jDriver(
        os.Getenv("NEO4J_URI"),
        os.Getenv("NEO4J_USER"),
        os.Getenv("NEO4J_PASSWORD"),
    )
    defer db.Close(ctx)

    // OpenAI for LLM and embeddings
    apiKey := os.Getenv("OPENAI_API_KEY")
    llmClient, _ := nlp.NewOpenAIClient(apiKey, nlp.Config{Model: "gpt-4o-mini"})
    embedderClient := embedder.NewOpenAIEmbedder(apiKey, embedder.Config{
        Model: "text-embedding-3-small",
    })

    client, _ := predicato.NewClient(db, llmClient, embedderClient, &predicato.Config{
        GroupID:  "my-app",
        TimeZone: time.UTC,
    }, nil)
    defer client.Close(ctx)

    // Same API as internal stack
    client.Add(ctx, []predicato.Episode{{
        ID:      "meeting-1",
        Content: "Alice mentioned the API redesign is blocked.",
        // ...
    }})
}
```

## Installation

```bash
go get github.com/soundprediction/predicato
```

### Building with Ladybug (Embedded Graph Database)

Predicato uses CGO for the Ladybug embedded graph database. Use Make for the easiest setup:

```bash
# Clone the repository
git clone https://github.com/soundprediction/predicato
cd predicato

# Download native libraries + build
make build

# Run tests
make test

# Build CLI binary
make build-cli
```

#### Manual Build (without Make)

```bash
# Step 1: Download Ladybug library
go generate ./cmd/main.go

# Step 2: Build with CGO flags
export CGO_LDFLAGS="-L$(pwd)/cmd/lib-ladybug -Wl,-rpath,$(pwd)/cmd/lib-ladybug"
go build -tags system_ladybug ./...
```

### Building Without CGO

Many packages work without CGO dependencies:

```bash
# Build core packages (no CGO required)
go build ./pkg/factstore/...
go build ./pkg/embedder/...
go build ./pkg/nlp/...

# Run pure Go tests
make test-nocgo
```

### Prerequisites

**Internal stack (Ladybug embedded database):**
- Go 1.21+
- GCC (for CGO compilation)
- Make (recommended)
- ~4GB RAM for local models

**External APIs only (no CGO needed):**
- Go 1.21+
- API keys for your chosen providers

## Examples

| Example | Description |
|---------|-------------|
| [`examples/basic/`](examples/basic/) | Full internal stack - Ladybug + RustBert + EmbedEverything + Reranking |
| [`examples/chat/`](examples/chat/) | Interactive chat with local models |
| [`examples/external_apis/`](examples/external_apis/) | Neo4j + OpenAI integration |

## Architecture

```
predicato/
├── pkg/driver/        # Graph databases (Ladybug, Neo4j, Memgraph)
├── pkg/embedder/      # Embedding providers (EmbedEverything, OpenAI, Gemini)
├── pkg/crossencoder/  # Reranking (EmbedEverything, Jina, LLM-based)
├── pkg/rustbert/      # Local text generation (GPT-2, NER, summarization)
├── pkg/nlp/           # LLM clients (OpenAI-compatible APIs)
├── pkg/search/        # Hybrid search (semantic + BM25 + graph traversal)
├── pkg/factstore/     # Versioned fact storage (PostgreSQL/DoltGres + VectorChord)
└── pkg/types/         # Core types (nodes, edges, episodes)
```

## Internal Services Stack

We rely on golang bindings for prediction models implemented originally in Rust. In particular we use https://github.com/guillaume-be/rust-bert (RustBert -> go-rust-bert), https://github.com/fbilhaut/gline-rs (Gline-rs), and https://github.com/StarlightSearch/EmbedAnything (EmbedEverything -> go-embed-everything). Please see upstream repositories for more details on models supported. Predicato will automatically download models on first use and cache to `~/.cache/huggingface/`.

Here is an example configuration and the model sizes involved:

| Component | Model | Download Size |
|-----------|-------|---------------|
| Embeddings | `qwen/qwen3-embedding-0.6b` | ~600MB |
| Reranking | `zhiqing/Qwen3-Reranker-0.6B-ONNX` | ~600MB |
| Text Generation | GPT-2 | ~500MB |

Models download automatically on first use and cache to `~/.cache/huggingface/`.

## Key Features

**Temporal Knowledge Graph**
- Bi-temporal model: `created_at` (when recorded) vs `valid_from/valid_to` (when true)
- Automatic invalidation of contradicting facts
- Historical queries: "what did we know about X as of date Y?"

**Hybrid Search**
- Semantic similarity (cosine distance on embeddings)
- BM25 keyword matching
- Graph traversal (BFS expansion through relationships)
- 5 reranking strategies: RRF, MMR, cross-encoder, node distance, episode mentions

**Production Ready**
- Circuit breakers with provider fallback
- Token usage tracking and cost calculation
- Error telemetry with DB persistence

## Fact Storage & RAG

Predicato includes a **fact storage system** for extracted entities and relationships that can be used independently for RAG (Retrieval-Augmented Generation) without requiring graph queries.

### PostgreSQL Backend

The fact storage uses PostgreSQL-compatible databases with **VectorChord** for native vector similarity search:

| Mode | Database | Use Case |
|------|----------|----------|
| **Embedded** | DoltGres | Development, single-node deployment |
| **External** | PostgreSQL + VectorChord | Production, managed databases (RDS, Cloud SQL) |

If no external PostgreSQL is configured, Predicato automatically uses **DoltGres** (embedded PostgreSQL-compatible database with git-like versioning).

### Configuration

```go
// Option 1: Automatic embedded DoltGres (no config needed)
client, _ := predicato.NewClient(db, llm, embedder, &predicato.Config{
    GroupID: "my-app",
}, nil)

// Option 2: External PostgreSQL with VectorChord
client, _ := predicato.NewClient(db, llm, embedder, &predicato.Config{
    GroupID: "my-app",
    FactStoreConfig: &factstore.FactStoreConfig{
        Type:             "postgres",
        ConnectionString: "postgres://user:pass@localhost:5432/facts?sslmode=disable",
    },
}, nil)
```

### RAG Search (without Graph)

For simpler RAG use cases that don't need relationship traversal:

```go
// Search extracted facts directly (no graph queries)
results, _ := client.SearchFacts(ctx, "API design patterns", &types.SearchConfig{
    Limit:    10,
    MinScore: 0.7,
})

for _, node := range results.Nodes {
    fmt.Printf("Found: %s (score: %.2f)\n", node.Name, node.Score)
}
```

This performs hybrid search (vector similarity + keyword matching) using VectorChord and PostgreSQL full-text search.

## CLI & Server

```bash
# Build CLI
make build-cli

# Start HTTP server
./bin/predicato server --port 8080

# API endpoints
POST /api/v1/ingest/messages  # Add content
POST /api/v1/search           # Search knowledge graph
GET  /api/v1/episodes/:id     # Get episodes
```

## Documentation

- [Getting Started](docs/GETTING_STARTED.md)
- [API Reference](docs/API_REFERENCE.md)
- [Ladybug Setup](docs/ladybug_SETUP.md)
- [FAQ](docs/FAQ.md)

## License

Apache 2.0

## Acknowledgments

Inspired by [Graphiti](https://github.com/getzep/graphiti) by Zep.
